{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiyu-cheng/6895_Visual_Sentiment_Prediction/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tmWCd5sXtRI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models, datasets\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.autograd import Variable\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCz3MqAwXwkr"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/data/zipdata.zip' -d '/content/drive/MyDrive/data/image_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XNEiup01p6H",
        "outputId": "d1980615-3121-4551-d830-7217e42f9213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oBWNFxuYSm8"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(48),        # Resize the image to 256x256 pixels\n",
        "    #transforms.CenterCrop(224),   # Crop the center 224x224 pixels\n",
        "    transforms.ToTensor(),        # Convert the image to a PyTorch tensor\n",
        "    # transforms.Normalize(         # Normalize the image\n",
        "    #     mean=[0.485, 0.456, 0.406],\n",
        "    #     std=[0.229, 0.224, 0.225]\n",
        "    # )\n",
        "])\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/image_data'\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRhmwmp4YVOv"
      },
      "outputs": [],
      "source": [
        "total_count=len(dataset)\n",
        "train_count = int(0.7 * total_count) \n",
        "valid_count = total_count - train_count \n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset=dataset, lengths=[train_count, valid_count])\n",
        "batch_size=16\n",
        "train_dataset_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  \n",
        "valid_dataset_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False) \n",
        "dataloaders = {'train': train_dataset_loader, 'valid': valid_dataset_loader}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYL_qtAiYXRV"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer,device, num_epochs=50):\n",
        "    since = time.time()\n",
        "    best_acc = 0\n",
        "    model.to(device)\n",
        "\n",
        "    val_acc_history = []\n",
        "    train_acc_history = []\n",
        "\n",
        "    test_acc_history = []\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  \n",
        "            else:\n",
        "                model.eval()   \n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "          \n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                #print(inputs.shape)\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "           \n",
        "                optimizer.zero_grad()\n",
        "            \n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "               \n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            \n",
        "            \n",
        "            time_elapsed = time.time() - since\n",
        "   \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            if phase == 'valid':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                valid_losses.append(epoch_loss)\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc)\n",
        "                train_losses.append(epoch_loss)\n",
        "            \n",
        "\n",
        "\n",
        "    return model, val_acc_history, train_acc_history,valid_losses, train_losses\n",
        "\n",
        "\n",
        "# define plot accuracy and loss\n",
        "def plot_acc_loss(val_acc_history, train_acc_history,valid_losses, train_losses):\n",
        "  val_acc=[]\n",
        "  for i in val_acc_history:\n",
        "    val_acc.append(i.cpu().data.numpy())\n",
        "  train_acc=[]\n",
        "  for i in train_acc_history:\n",
        "    train_acc.append(i.cpu().data.numpy())\n",
        "  test_acc=[]\n",
        "\n",
        "  \n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(range(len(val_acc)),val_acc,label='val_acc')\n",
        "  plt.plot(range(len(train_acc)),train_acc,label='train_acc')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('acc')\n",
        "  plt.legend()\n",
        "  \n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(range(len(valid_losses)),valid_losses,label='val_loss')\n",
        "  plt.plot(range(len(train_losses)),train_losses,label='train_loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpmtky05YXrv",
        "outputId": "04d601fa-ddc6-4775-ce97-a50db145dc51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xcCE6TshYZAO",
        "outputId": "735876a9-9eb1-45b6-ad0f-7ec8972665d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/99\n",
            "----------\n",
            "train Loss: 3.3157 Acc: 0.0686\n",
            "valid Loss: 3.1492 Acc: 0.0675\n",
            "Epoch 1/99\n",
            "----------\n",
            "train Loss: 3.2197 Acc: 0.0784\n",
            "valid Loss: 3.1048 Acc: 0.0931\n",
            "Epoch 2/99\n",
            "----------\n",
            "train Loss: 3.1771 Acc: 0.0896\n",
            "valid Loss: 3.5922 Acc: 0.1019\n",
            "Epoch 3/99\n",
            "----------\n",
            "train Loss: 3.1407 Acc: 0.0989\n",
            "valid Loss: 3.3183 Acc: 0.1237\n",
            "Epoch 4/99\n",
            "----------\n",
            "train Loss: 3.1299 Acc: 0.1036\n",
            "valid Loss: 38.4826 Acc: 0.0872\n",
            "Epoch 5/99\n",
            "----------\n",
            "train Loss: 3.1371 Acc: 0.1037\n",
            "valid Loss: 4.5954 Acc: 0.1043\n",
            "Epoch 6/99\n",
            "----------\n",
            "train Loss: 3.0904 Acc: 0.1195\n",
            "valid Loss: 2.9814 Acc: 0.1296\n",
            "Epoch 7/99\n",
            "----------\n",
            "train Loss: 3.0682 Acc: 0.1158\n",
            "valid Loss: 2.9830 Acc: 0.1429\n",
            "Epoch 8/99\n",
            "----------\n",
            "train Loss: 3.0484 Acc: 0.1254\n",
            "valid Loss: 3.4241 Acc: 0.1509\n",
            "Epoch 9/99\n",
            "----------\n",
            "train Loss: 3.0241 Acc: 0.1292\n",
            "valid Loss: 2.9230 Acc: 0.1585\n",
            "Epoch 10/99\n",
            "----------\n",
            "train Loss: 2.9905 Acc: 0.1415\n",
            "valid Loss: 3.2174 Acc: 0.1400\n",
            "Epoch 11/99\n",
            "----------\n",
            "train Loss: 2.9747 Acc: 0.1412\n",
            "valid Loss: 3.4602 Acc: 0.1358\n",
            "Epoch 12/99\n",
            "----------\n",
            "train Loss: 2.9488 Acc: 0.1525\n",
            "valid Loss: 3.0992 Acc: 0.1744\n",
            "Epoch 13/99\n",
            "----------\n",
            "train Loss: 2.8810 Acc: 0.1757\n",
            "valid Loss: 2.8575 Acc: 0.1883\n",
            "Epoch 14/99\n",
            "----------\n",
            "train Loss: 2.8447 Acc: 0.1820\n",
            "valid Loss: 3.1481 Acc: 0.1544\n",
            "Epoch 15/99\n",
            "----------\n",
            "train Loss: 2.8414 Acc: 0.1864\n",
            "valid Loss: 2.9338 Acc: 0.1844\n",
            "Epoch 16/99\n",
            "----------\n",
            "train Loss: 2.7993 Acc: 0.1974\n",
            "valid Loss: 3.1543 Acc: 0.1812\n",
            "Epoch 17/99\n",
            "----------\n",
            "train Loss: 2.7631 Acc: 0.2085\n",
            "valid Loss: 2.8390 Acc: 0.1983\n",
            "Epoch 18/99\n",
            "----------\n",
            "train Loss: 2.7172 Acc: 0.2193\n",
            "valid Loss: 2.8373 Acc: 0.2060\n",
            "Epoch 19/99\n",
            "----------\n",
            "train Loss: 2.6647 Acc: 0.2276\n",
            "valid Loss: 2.9577 Acc: 0.1895\n",
            "Epoch 20/99\n",
            "----------\n",
            "train Loss: 2.6563 Acc: 0.2399\n",
            "valid Loss: 2.8614 Acc: 0.2062\n",
            "Epoch 21/99\n",
            "----------\n",
            "train Loss: 2.6751 Acc: 0.2343\n",
            "valid Loss: 2.8790 Acc: 0.1986\n",
            "Epoch 22/99\n",
            "----------\n",
            "train Loss: 2.5973 Acc: 0.2535\n",
            "valid Loss: 3.3136 Acc: 0.2104\n",
            "Epoch 23/99\n",
            "----------\n",
            "train Loss: 2.5342 Acc: 0.2711\n",
            "valid Loss: 2.9198 Acc: 0.2089\n",
            "Epoch 24/99\n",
            "----------\n",
            "train Loss: 2.5129 Acc: 0.2711\n",
            "valid Loss: 2.8913 Acc: 0.2136\n",
            "Epoch 25/99\n",
            "----------\n",
            "train Loss: 2.4602 Acc: 0.2876\n",
            "valid Loss: 2.9599 Acc: 0.2130\n",
            "Epoch 26/99\n",
            "----------\n",
            "train Loss: 2.3688 Acc: 0.3138\n",
            "valid Loss: 2.9115 Acc: 0.2157\n",
            "Epoch 27/99\n",
            "----------\n",
            "train Loss: 2.2605 Acc: 0.3365\n",
            "valid Loss: 3.0168 Acc: 0.2189\n",
            "Epoch 28/99\n",
            "----------\n",
            "train Loss: 2.1742 Acc: 0.3628\n",
            "valid Loss: 2.9877 Acc: 0.2195\n",
            "Epoch 29/99\n",
            "----------\n",
            "train Loss: 2.0534 Acc: 0.3926\n",
            "valid Loss: 3.0788 Acc: 0.2142\n",
            "Epoch 30/99\n",
            "----------\n",
            "train Loss: 1.9928 Acc: 0.4134\n",
            "valid Loss: 3.1716 Acc: 0.2127\n",
            "Epoch 31/99\n",
            "----------\n",
            "train Loss: 1.8818 Acc: 0.4518\n",
            "valid Loss: 3.2218 Acc: 0.2110\n",
            "Epoch 32/99\n",
            "----------\n",
            "train Loss: 1.6968 Acc: 0.4921\n",
            "valid Loss: 3.2509 Acc: 0.2145\n",
            "Epoch 33/99\n",
            "----------\n",
            "train Loss: 1.6236 Acc: 0.5105\n",
            "valid Loss: 3.4139 Acc: 0.2065\n",
            "Epoch 34/99\n",
            "----------\n",
            "train Loss: 1.4835 Acc: 0.5530\n",
            "valid Loss: 3.4956 Acc: 0.2133\n",
            "Epoch 35/99\n",
            "----------\n",
            "train Loss: 1.4624 Acc: 0.5628\n",
            "valid Loss: 3.6586 Acc: 0.2139\n",
            "Epoch 36/99\n",
            "----------\n",
            "train Loss: 1.3478 Acc: 0.5901\n",
            "valid Loss: 3.7083 Acc: 0.2095\n",
            "Epoch 37/99\n",
            "----------\n",
            "train Loss: 1.2083 Acc: 0.6309\n",
            "valid Loss: 3.8919 Acc: 0.2062\n",
            "Epoch 38/99\n",
            "----------\n",
            "train Loss: 1.1213 Acc: 0.6639\n",
            "valid Loss: 4.1700 Acc: 0.2065\n",
            "Epoch 39/99\n",
            "----------\n",
            "train Loss: 0.9189 Acc: 0.7169\n",
            "valid Loss: 4.2722 Acc: 0.2009\n",
            "Epoch 40/99\n",
            "----------\n",
            "train Loss: 0.8622 Acc: 0.7335\n",
            "valid Loss: 4.4630 Acc: 0.1853\n",
            "Epoch 41/99\n",
            "----------\n",
            "train Loss: 0.7691 Acc: 0.7619\n",
            "valid Loss: 4.5413 Acc: 0.2036\n",
            "Epoch 42/99\n",
            "----------\n",
            "train Loss: 0.7176 Acc: 0.7776\n",
            "valid Loss: 4.7942 Acc: 0.2006\n",
            "Epoch 43/99\n",
            "----------\n",
            "train Loss: 0.6864 Acc: 0.7877\n",
            "valid Loss: 4.9163 Acc: 0.2024\n",
            "Epoch 44/99\n",
            "----------\n",
            "train Loss: 0.6302 Acc: 0.8093\n",
            "valid Loss: 5.0492 Acc: 0.1953\n",
            "Epoch 45/99\n",
            "----------\n",
            "train Loss: 0.5657 Acc: 0.8243\n",
            "valid Loss: 5.3631 Acc: 0.1953\n",
            "Epoch 46/99\n",
            "----------\n",
            "train Loss: 0.5203 Acc: 0.8357\n",
            "valid Loss: 5.5255 Acc: 0.1930\n",
            "Epoch 47/99\n",
            "----------\n",
            "train Loss: 0.5612 Acc: 0.8287\n",
            "valid Loss: 4.9840 Acc: 0.1836\n",
            "Epoch 48/99\n",
            "----------\n",
            "train Loss: 0.5389 Acc: 0.8339\n",
            "valid Loss: 5.2326 Acc: 0.1924\n",
            "Epoch 49/99\n",
            "----------\n",
            "train Loss: 0.4296 Acc: 0.8693\n",
            "valid Loss: 5.4236 Acc: 0.2036\n",
            "Epoch 50/99\n",
            "----------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2d80d64327eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-7a4282dd6548>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[has-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use cumulative moving average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "model = models.resnet50(pretrained=True)  #Use the resnet18 model\n",
        "num_ftrs =model .fc.in_features #Modify the number of model categories\n",
        "model.fc = nn.Sequential(nn.Dropout(0.6),nn.Linear(num_ftrs, 24))\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "cost_fun = nn.CrossEntropyLoss().to(device) \n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3) \n",
        "model = model.to(device)\n",
        "model, val_acc_history, train_acc_history,valid_losses, train_losses= train_model(model, dataloaders, cost_fun, optimizer, device,num_epochs=100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}