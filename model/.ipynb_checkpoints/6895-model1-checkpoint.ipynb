{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93cf1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models, datasets\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df06e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155e5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),        # Resize the image to 256x256 pixels\n",
    "    transforms.CenterCrop(224),   # Crop the center 224x224 pixels\n",
    "    transforms.ToTensor()        # Convert the image to a PyTorch tensor\n",
    "])\n",
    "batch_size = 128\n",
    "data_dir = '~/6895_Visual_Sentiment_Prediction/dataset'\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "# train_dataset = datasets.ImageFolder('~/Desktop/6895/Images/train/', transform=transform)\n",
    "# valid_dataset = datasets.ImageFolder('~/Desktop/6895/Images/validation/', transform=transform)\n",
    "total_count = len(dataset)\n",
    "train_count = int(0.7 * total_count) \n",
    "valid_count = total_count - train_count \n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset=dataset, lengths=[train_count, valid_count])\n",
    "train_dataset_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)  \n",
    "valid_dataset_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = batch_size, shuffle = False) \n",
    "dataloaders = {'train': train_dataset_loader, 'valid': valid_dataset_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d049b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer,device, num_epochs=50):\n",
    "    since = time.time()\n",
    "    best_acc = 0\n",
    "    model.to(device)\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    test_acc_history = []\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        SAVE_PATH = os.path.join(\"models\", 'm' + \".pt\")\n",
    "        torch.save(model, SAVE_PATH)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "          \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                #print(inputs.shape)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "           \n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "               \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            \n",
    "            time_elapsed = time.time() - since\n",
    "   \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'valid':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                valid_losses.append(epoch_loss)\n",
    "\n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_losses.append(epoch_loss)\n",
    "            \n",
    "\n",
    "\n",
    "    return model, val_acc_history, train_acc_history,valid_losses, train_losses\n",
    "\n",
    "\n",
    "# define plot accuracy and loss\n",
    "def plot_acc_loss(val_acc_history, train_acc_history,valid_losses, train_losses):\n",
    "    val_acc=[]\n",
    "    for i in val_acc_history:\n",
    "        val_acc.append(i.cpu().data.numpy())\n",
    "    train_acc=[]\n",
    "    for i in train_acc_history:\n",
    "        train_acc.append(i.cpu().data.numpy())\n",
    "    test_acc=[]\n",
    "\n",
    "  \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(range(len(val_acc)),val_acc,label='val_acc')\n",
    "    plt.plot(range(len(train_acc)),train_acc,label='train_acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('acc')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(range(len(valid_losses)),valid_losses,label='val_loss')\n",
    "    plt.plot(range(len(train_losses)),train_losses,label='train_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdfba90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_5627/3661112120.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplot_acc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/tmp/ipykernel_5627/2528494087.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mSAVE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAVE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained = True) # Use the resnet18 model\n",
    "num_ftrs = model.fc.in_features # Modify the number of model categories\n",
    "model.fc = nn.Sequential(nn.Dropout(0.5), nn.Linear(num_ftrs, 24))\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "cost_fun = nn.CrossEntropyLoss().to(device) \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-5) \n",
    "model = model.to(device = 'cuda', dtype = torch.float32)\n",
    "model, val_acc_history, train_acc_history,valid_losses, train_losses = train_model(model, dataloaders, cost_fun, optimizer, device,num_epochs=100)\n",
    "plot_acc_loss(val_acc_history, train_acc_history,valid_losses, train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233081e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
