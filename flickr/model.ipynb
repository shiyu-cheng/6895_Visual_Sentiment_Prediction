{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiyu-cheng/6895_Visual_Sentiment_Prediction/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tmWCd5sXtRI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models, datasets\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.autograd import Variable\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCz3MqAwXwkr"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/data/zipdata.zip' -d '/content/drive/MyDrive/data/image_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XNEiup01p6H",
        "outputId": "6ccc9be8-4082-4c8b-9d49-6a0c9fe12d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "Atdi25NEqFz0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmdir /content/drive/MyDrive/6895/data/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "gTJsbDiClbTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864fda09-f72a-469d-c916-f856d6bf6de9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmdir: failed to remove '/content/drive/MyDrive/6895/data/.ipynb_checkpoints': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7oBWNFxuYSm8"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(48),        # Resize the image to 256x256 pixels\n",
        "    #transforms.CenterCrop(224),   # Crop the center 224x224 pixels\n",
        "    transforms.ToTensor(),        # Convert the image to a PyTorch tensor\n",
        "    # transforms.Normalize(         # Normalize the image\n",
        "    #     mean=[0.485, 0.456, 0.406],\n",
        "    #     std=[0.229, 0.224, 0.225]\n",
        "    # )\n",
        "])\n",
        "\n",
        "# data_dir = '/content/drive/MyDrive/Colab Notebooks/image_data'\n",
        "data_dir = '/content/drive/MyDrive/6895/data'\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yKValDWh6QT",
        "outputId": "fd155954-7f04-46a3-ab0c-c181aba297f8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 971\n",
              "    Root location: /content/drive/MyDrive/6895/data\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=48, interpolation=bilinear, max_size=None, antialias=None)\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hRhmwmp4YVOv"
      },
      "outputs": [],
      "source": [
        "total_count=len(dataset)\n",
        "train_count = int(0.7 * total_count) \n",
        "valid_count = total_count - train_count \n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset=dataset, lengths=[train_count, valid_count])\n",
        "batch_size=16\n",
        "train_dataset_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  \n",
        "valid_dataset_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False) \n",
        "dataloaders = {'train': train_dataset_loader, 'valid': valid_dataset_loader}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "CYL_qtAiYXRV"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer,device, num_epochs=50):\n",
        "    since = time.time()\n",
        "    best_acc = 0\n",
        "    model.to(device)\n",
        "\n",
        "    val_acc_history = []\n",
        "    train_acc_history = []\n",
        "\n",
        "    test_acc_history = []\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  \n",
        "            else:\n",
        "                model.eval()   \n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "          \n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                #print(inputs.shape)\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "           \n",
        "                optimizer.zero_grad()\n",
        "            \n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "               \n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "            \n",
        "            \n",
        "            time_elapsed = time.time() - since\n",
        "   \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            if phase == 'valid':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                valid_losses.append(epoch_loss)\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc)\n",
        "                train_losses.append(epoch_loss)\n",
        "            \n",
        "\n",
        "\n",
        "    return model, val_acc_history, train_acc_history,valid_losses, train_losses\n",
        "\n",
        "\n",
        "# define plot accuracy and loss\n",
        "def plot_acc_loss(val_acc_history, train_acc_history,valid_losses, train_losses):\n",
        "  val_acc=[]\n",
        "  for i in val_acc_history:\n",
        "    val_acc.append(i.cpu().data.numpy())\n",
        "  train_acc=[]\n",
        "  for i in train_acc_history:\n",
        "    train_acc.append(i.cpu().data.numpy())\n",
        "  test_acc=[]\n",
        "\n",
        "  \n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(range(len(val_acc)),val_acc,label='val_acc')\n",
        "  plt.plot(range(len(train_acc)),train_acc,label='train_acc')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('acc')\n",
        "  plt.legend()\n",
        "  \n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(range(len(valid_losses)),valid_losses,label='val_loss')\n",
        "  plt.plot(range(len(train_losses)),train_losses,label='train_loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpmtky05YXrv",
        "outputId": "e41843d4-435f-4063-9fc6-b5362edeb232"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcCE6TshYZAO",
        "outputId": "e80d742c-cbc7-4b4c-a121-a13d3054322d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/39\n",
            "----------\n",
            "train Loss: 0.9705 Acc: 0.5538\n",
            "valid Loss: 0.7795 Acc: 0.6130\n",
            "Epoch 1/39\n",
            "----------\n",
            "train Loss: 0.7076 Acc: 0.6495\n",
            "valid Loss: 0.9561 Acc: 0.5479\n",
            "Epoch 2/39\n",
            "----------\n",
            "train Loss: 0.7907 Acc: 0.6495\n",
            "valid Loss: 0.6404 Acc: 0.6541\n",
            "Epoch 3/39\n",
            "----------\n",
            "train Loss: 0.6819 Acc: 0.6966\n",
            "valid Loss: 0.7843 Acc: 0.6267\n",
            "Epoch 4/39\n",
            "----------\n",
            "train Loss: 0.6995 Acc: 0.6981\n",
            "valid Loss: 0.7346 Acc: 0.6438\n",
            "Epoch 5/39\n",
            "----------\n",
            "train Loss: 0.6016 Acc: 0.7216\n",
            "valid Loss: 0.8173 Acc: 0.5788\n",
            "Epoch 6/39\n",
            "----------\n",
            "train Loss: 0.6771 Acc: 0.6745\n",
            "valid Loss: 0.7202 Acc: 0.6199\n",
            "Epoch 7/39\n",
            "----------\n",
            "train Loss: 0.6800 Acc: 0.6701\n",
            "valid Loss: 0.8747 Acc: 0.6096\n",
            "Epoch 8/39\n",
            "----------\n",
            "train Loss: 0.6897 Acc: 0.6524\n",
            "valid Loss: 1.1781 Acc: 0.5890\n",
            "Epoch 9/39\n",
            "----------\n",
            "train Loss: 0.6938 Acc: 0.6716\n",
            "valid Loss: 0.9770 Acc: 0.5993\n",
            "Epoch 10/39\n",
            "----------\n",
            "train Loss: 0.6429 Acc: 0.7054\n",
            "valid Loss: 0.7051 Acc: 0.6233\n",
            "Epoch 11/39\n",
            "----------\n",
            "train Loss: 0.6670 Acc: 0.6878\n",
            "valid Loss: 0.7519 Acc: 0.6575\n",
            "Epoch 12/39\n",
            "----------\n",
            "train Loss: 0.6556 Acc: 0.7143\n",
            "valid Loss: 0.8779 Acc: 0.6096\n",
            "Epoch 13/39\n",
            "----------\n",
            "train Loss: 0.6686 Acc: 0.7099\n",
            "valid Loss: 0.6759 Acc: 0.6301\n",
            "Epoch 14/39\n",
            "----------\n",
            "train Loss: 0.6261 Acc: 0.7275\n",
            "valid Loss: 0.7666 Acc: 0.6644\n",
            "Epoch 15/39\n",
            "----------\n",
            "train Loss: 0.5373 Acc: 0.7599\n",
            "valid Loss: 0.7521 Acc: 0.5788\n",
            "Epoch 16/39\n",
            "----------\n",
            "train Loss: 0.5010 Acc: 0.7658\n",
            "valid Loss: 0.8036 Acc: 0.6507\n",
            "Epoch 17/39\n",
            "----------\n",
            "train Loss: 0.3877 Acc: 0.8336\n",
            "valid Loss: 0.9456 Acc: 0.6438\n",
            "Epoch 18/39\n",
            "----------\n",
            "train Loss: 0.4401 Acc: 0.8130\n",
            "valid Loss: 1.9390 Acc: 0.6164\n",
            "Epoch 19/39\n",
            "----------\n",
            "train Loss: 0.4431 Acc: 0.8395\n",
            "valid Loss: 0.8635 Acc: 0.6199\n",
            "Epoch 20/39\n",
            "----------\n",
            "train Loss: 0.2825 Acc: 0.8792\n",
            "valid Loss: 0.9339 Acc: 0.6164\n",
            "Epoch 21/39\n",
            "----------\n",
            "train Loss: 0.2255 Acc: 0.9249\n",
            "valid Loss: 1.2490 Acc: 0.6336\n",
            "Epoch 22/39\n",
            "----------\n",
            "train Loss: 0.2648 Acc: 0.8969\n",
            "valid Loss: 0.9815 Acc: 0.6370\n",
            "Epoch 23/39\n",
            "----------\n",
            "train Loss: 0.2450 Acc: 0.9057\n",
            "valid Loss: 0.9472 Acc: 0.6096\n",
            "Epoch 24/39\n",
            "----------\n",
            "train Loss: 0.1486 Acc: 0.9411\n",
            "valid Loss: 1.0205 Acc: 0.6370\n",
            "Epoch 25/39\n",
            "----------\n",
            "train Loss: 0.0700 Acc: 0.9794\n",
            "valid Loss: 1.3163 Acc: 0.6199\n",
            "Epoch 26/39\n",
            "----------\n",
            "train Loss: 0.0478 Acc: 0.9853\n",
            "valid Loss: 1.3497 Acc: 0.6164\n",
            "Epoch 27/39\n",
            "----------\n",
            "train Loss: 0.0850 Acc: 0.9750\n",
            "valid Loss: 1.5767 Acc: 0.6712\n",
            "Epoch 28/39\n",
            "----------\n",
            "train Loss: 0.1664 Acc: 0.9337\n",
            "valid Loss: 1.4127 Acc: 0.6199\n",
            "Epoch 29/39\n",
            "----------\n",
            "train Loss: 0.1219 Acc: 0.9632\n",
            "valid Loss: 1.1856 Acc: 0.6541\n",
            "Epoch 30/39\n",
            "----------\n",
            "train Loss: 0.1438 Acc: 0.9573\n",
            "valid Loss: 1.0362 Acc: 0.6610\n",
            "Epoch 31/39\n",
            "----------\n",
            "train Loss: 0.0703 Acc: 0.9809\n",
            "valid Loss: 1.3114 Acc: 0.6336\n",
            "Epoch 32/39\n",
            "----------\n",
            "train Loss: 0.0435 Acc: 0.9823\n",
            "valid Loss: 1.3532 Acc: 0.6747\n",
            "Epoch 33/39\n",
            "----------\n",
            "train Loss: 0.1113 Acc: 0.9573\n",
            "valid Loss: 1.2364 Acc: 0.6507\n",
            "Epoch 34/39\n",
            "----------\n",
            "train Loss: 0.0498 Acc: 0.9867\n",
            "valid Loss: 1.3103 Acc: 0.6404\n",
            "Epoch 35/39\n",
            "----------\n",
            "train Loss: 0.0805 Acc: 0.9750\n",
            "valid Loss: 1.3691 Acc: 0.6301\n",
            "Epoch 36/39\n",
            "----------\n",
            "train Loss: 0.0823 Acc: 0.9705\n",
            "valid Loss: 1.3285 Acc: 0.6336\n",
            "Epoch 37/39\n",
            "----------\n",
            "train Loss: 0.1543 Acc: 0.9455\n",
            "valid Loss: 1.4020 Acc: 0.5856\n",
            "Epoch 38/39\n",
            "----------\n",
            "train Loss: 0.0690 Acc: 0.9838\n",
            "valid Loss: 1.2175 Acc: 0.6404\n",
            "Epoch 39/39\n",
            "----------\n",
            "train Loss: 0.0291 Acc: 0.9897\n",
            "valid Loss: 1.3112 Acc: 0.6404\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "model = models.resnet50(pretrained=True)  #Use the resnet18 model\n",
        "num_ftrs =model .fc.in_features #Modify the number of model categories\n",
        "model.fc = nn.Sequential(nn.Dropout(0.6),nn.Linear(num_ftrs, 24))\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "cost_fun = nn.CrossEntropyLoss().to(device) \n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3) \n",
        "model = model.to(device)\n",
        "model, val_acc_history, train_acc_history,valid_losses, train_losses= train_model(model, dataloaders, cost_fun, optimizer, device,num_epochs=40)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}