{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mklHcjqfY4aY4ootyuIGbsYUUnPcMOfD",
      "authorship_tag": "ABX9TyO0BJJQ8EXhiiBFfxd9tJM7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiyu-cheng/6895_Visual_Sentiment_Prediction/blob/master/image_query.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install flickrapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qhp3Ko24oNC",
        "outputId": "36893594-326e-4bd6-a1fa-67b0347d8244"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flickrapi\n",
            "  Downloading flickrapi-2.4.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.8/dist-packages (from flickrapi) (1.15.0)\n",
            "Collecting requests-toolbelt>=0.3.1\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from flickrapi) (2.25.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from flickrapi) (1.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.2.1->flickrapi) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.2.1->flickrapi) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.2.1->flickrapi) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.2.1->flickrapi) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.4.0->flickrapi) (3.2.2)\n",
            "Installing collected packages: requests-toolbelt, flickrapi\n",
            "Successfully installed flickrapi-2.4.0 requests-toolbelt-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from pprint import pprint\n",
        "from flickrapi import FlickrAPI\n",
        "import urllib\n",
        "from PIL import Image\n",
        "import os\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "HTLir09x2J-A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/drive/MyDrive/6895/'"
      ],
      "metadata": {
        "id": "cWc6LDhIcuKr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feelings = (\n",
        "    \"Joy\",\n",
        "    \"Trust\",\n",
        "    \"Fear\",\n",
        "    \"Surprise\",\n",
        "    \"Sadness\",\n",
        "    \"Disgust\",\n",
        "    \"Anger\",\n",
        "    \"Anticipation\",\n",
        "    \"Love\",\n",
        "    \"Submission\",\n",
        "    \"Awe\",\n",
        "    \"Disapproval\",\n",
        "    \"Remorse\",\n",
        "    \"Contempt\",\n",
        "    \"Aggressiveness\",\n",
        "    \"Optimism\",\n",
        "    \"Guilt\",\n",
        "    \"Shame\",\n",
        "    \"Envy\",\n",
        "    \"Indifference\",\n",
        "    \"Serenity\",\n",
        "    \"Boredom\",\n",
        "    \"Irritation\",\n",
        "    \"Pessimism\"\n",
        ")"
      ],
      "metadata": {
        "id": "WS65nIpP0jTK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5bM8whQk4PwI"
      },
      "outputs": [],
      "source": [
        "#search images\n",
        "FLICKR_PUBLIC = 'f8b9cd454275fca40682a0e602c67073'\n",
        "FLICKR_SECRET = 'cab676a88194ebae'\n",
        "\n",
        "flickr = FlickrAPI(FLICKR_PUBLIC, FLICKR_SECRET, format='parsed-json')\n",
        "#ATTENTION!!!\n",
        "#the flickr api has hugs! the offsets of image size categories are wrong... \n",
        "#To get url_s, which is the URL of small suqare 75x75 size image, \n",
        "#we have to use parameter url_sq\n",
        "extras = 'url_sq' #URL of small suqare 75x75 size image\n",
        "per_page = 100\n",
        "page = range(1,6)\n",
        "img_sz = 75\n",
        "feeling_dict = {}\n",
        "for feeling in feelings:\n",
        "  url_list = []\n",
        "  for i in page:\n",
        "    cats = flickr.photos.search(tags = feeling, per_page = per_page, page = i, extras = extras, sort = 'relevance')\n",
        "    photos = cats['photos']\n",
        "    # print(type(photos['photo']))\n",
        "    # pprint(photos)\n",
        "    for p in photos['photo']: #dict\n",
        "      url = p['url_sq']\n",
        "      height = p['height_sq']\n",
        "      width = p['width_sq']\n",
        "      if height != img_sz or width != img_sz:\n",
        "        continue\n",
        "      \n",
        "      url_list.append(url)\n",
        "\n",
        "  feeling_dict[feeling] = url_list\n",
        "# print(url_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download image\n",
        "# feeling_dr_set = set()\n",
        "img_file = 'images_flickr_tag_sort_by_relevance/'\n",
        "isExist = os.path.exists(directory + img_file)\n",
        "if not isExist:\n",
        "  os.mkdir(directory + img_file)\n",
        "for f in feeling_dict:\n",
        "  img_dr = directory + img_file + f\n",
        "  isExist = os.path.exists(img_dr)\n",
        "  if not isExist:\n",
        "    os.mkdir(img_dr)\n",
        "  # feeling_dr_set.add(img_dr)\n",
        "  for url in feeling_dict[f]:\n",
        "    img_name = url.split('/')[-1]\n",
        "    path = img_dr + '/' + img_name\n",
        "    if os.path.exists(path):\n",
        "      continue\n",
        "    # sleep(1)\n",
        "    try:\n",
        "      urllib.request.urlretrieve(url, path)\n",
        "      urllib.request.urlcleanup()\n",
        "    except Exception as e: \n",
        "      print(e)\n",
        "\n",
        "# Resize the image and overwrite it\n",
        "# image = Image.open('00001.jpg') \n",
        "# image = image.resize((img_sz, img_sz), Image.ANTIALIAS)\n",
        "# image.save('00001.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrgQZuSl4atq",
        "outputId": "b60b26c9-bfc1-4832-b7f9-b993ffed9d94"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP Error 504: Gateway Time-out\n",
            "HTTP Error 504: Gateway Time-out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#image to csv\n",
        "import numpy as np\n",
        "import matplotlib.image as img\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "csv_file = os.path.join(directory, 'images_flickr_tag/flickr_tag_relevence_img.csv')\n",
        "if os.path.exists(csv_file):\n",
        "  os.remove(os.path.join(directory, 'images_flickr_tag/flickr_tag_relevence_img.csv'))\n",
        "\n",
        "# iterate over files\n",
        "img_dr = directory + '/images_flickr_tag_sort_by_relevance/'\n",
        "for file in os.listdir(img_dr):\n",
        "  file = os.path.join(img_dr, file)\n",
        "  for filename in os.listdir(file):\n",
        "    # read an image\n",
        "    imageMat = img.imread(os.path.join(file, filename))\n",
        "    print(\"Image shape:\", imageMat.shape)\n",
        "    \n",
        "    # if image is colored (RGB)\n",
        "    if(imageMat.ndim == 3 and imageMat.shape[2] == 3):\n",
        "      \n",
        "      # reshape it from 3D matrice to 1D arraye\n",
        "      imageMat_reshape = imageMat.reshape(1,\n",
        "                                          -1)\n",
        "      print(\"Reshaping to 2D array:\",\n",
        "            imageMat_reshape.shape)\n",
        "    \n",
        "    # if image is grayscale\n",
        "    else:\n",
        "      continue\n",
        "        \n",
        "    mat_df = pd.DataFrame(imageMat_reshape)\n",
        "    mat_df['label'] = file.split('/')[-1]\n",
        " \n",
        "    # exporting dataframe to CSV file.\n",
        "    # mat_df.to_csv(os.path.join(directory, 'images/test2_img.csv'),\n",
        "    #               header = None,\n",
        "    #               index = None)\n",
        "    \n",
        "    if not os.path.exists(csv_file):\n",
        "      mat_df.to_csv(csv_file, index=False)\n",
        "    else:\n",
        "      mat_df.to_csv(csv_file, mode='a', index=False, header=False)\n",
        "    \n"
      ],
      "metadata": {
        "id": "tbgGnHEsZkiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step: use unsplash to update the dataset\n",
        "Awe"
      ],
      "metadata": {
        "id": "SPv-9CSNvgIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # retrieving matrice from the .csv file\n",
        "# loaded_2D_mat = np.loadtxt(directory + 'test_img.csv')\n",
        " \n",
        "# # reshaping it to 3D matrice\n",
        "# loaded_mat = loaded_2D_mat.reshape(loaded_2D_mat.shape[0],\n",
        "#                                    loaded_2D_mat.shape[1] // imageMat.shape[2],\n",
        "#                                    imageMat.shape[2])\n",
        " \n",
        "# print(\"Image shape of loaded Image:\",\n",
        "#       loaded_mat.shape)\n",
        " \n",
        "# # check if both matrice have same shape or not\n",
        "# if((imageMat == loaded_mat).all()):\n",
        "   \n",
        "#   print(\"\\n\\nYes\",\n",
        "#         \"The loaded matrice from CSV file is same as original image matrice\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQgvMuXdf-Qm",
        "outputId": "fad8ec17-64f1-4a23-ed87-ca562d831578"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape of loaded Image: (75, 75, 3)\n",
            "\n",
            "\n",
            "Yes The loaded matrice from CSV file is same as original image matrice\n"
          ]
        }
      ]
    }
  ]
}